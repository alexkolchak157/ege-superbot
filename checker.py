import re
import math
import html
import logging
from typing import List, Tuple, Dict, Any, Optional, Set
from collections import defaultdict
from telegram import InlineKeyboardMarkup, InlineKeyboardButton

logger = logging.getLogger(__name__)


class PlanBotData:
    def __init__(self, data: Dict[str, Any]):
        logger.info(">>> –í—Ö–æ–¥ –≤ PlanBotData.__init__")
        self._morph = None
        self.topics_by_block: Dict[str, List[Tuple[int, str]]] = defaultdict(list)
        self.topic_list_for_pagination: List[Tuple[int, str]] = []
        self.topic_index_map: Dict[int, str] = {}
        self.plans_data: Dict[str, Dict[str, Any]] = {}

        self._load_data(data)
        logger.info("<<< –í—ã—Ö–æ–¥ –∏–∑ PlanBotData.__init__")

    def _load_data(self, data: Dict[str, Any]):
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –ø–ª–∞–Ω–∞:
        - –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∫–∞–∫ —Ñ–æ—Ä–º–∞—Ç {"plans": {...}, "blocks": {...}}, —Ç–∞–∫ –∏ —Å–ø–∏—Å–æ–∫ —Ç–µ–º [{...}, ...]
        - –Ω–∞–ø–æ–ª–Ω—è–µ—Ç self.plans_data, self.topics_by_block, self.topic_list_for_pagination, self.topic_index_map
        """
        try:
            # --- –ï—Å–ª–∏ data —ç—Ç–æ —Å–ø–∏—Å–æ–∫ (—Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç) ---
            if isinstance(data, list):
                logger.warning("PlanBotData: data - —ç—Ç–æ —Å–ø–∏—Å–æ–∫, –ø—Ä–µ–æ–±—Ä–∞–∑—É—é –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä—É plans –∏ blocks")
                raw_plans = {}
                blocks = {}
                topics = []
                # –ö–∞–∂–¥—ã–π —ç–ª–µ–º–µ–Ω—Ç —Å–ø–∏—Å–∫–∞ ‚Äî —ç—Ç–æ —Ç–µ–º–∞ (dict: {topic: {–ø–æ–ª—è}})
                for obj in data:
                    if isinstance(obj, dict):
                        for topic, plan_data in obj.items():
                            raw_plans[topic] = plan_data
                            topics.append(topic)
                            # –ë–ª–æ–∫–∏ –º–æ–≥—É—Ç –±—ã—Ç—å –≤–Ω—É—Ç—Ä–∏ plan_data
                            block = plan_data.get("block", "–ë–µ–∑ –±–ª–æ–∫–∞")
                            blocks.setdefault(block, []).append(topic)
                data = {"plans": raw_plans, "blocks": blocks}
            # --- –ï—Å–ª–∏ data —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å ---
            raw_plans = data.get("plans", {})
            if not isinstance(raw_plans, dict):
                logger.error(f"–ö–ª—é—á 'plans' –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä—ë–º, –Ω–æ –ø–æ–ª—É—á–µ–Ω {type(raw_plans)}; —Å–±—Ä–∞—Å—ã–≤–∞–µ–º –≤ {{}}.")
                raw_plans = {}
            self.plans_data = raw_plans

            # 2. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–ª–æ–∫–∏ —Ç–µ–º (pagination)
            blocks = data.get("blocks", {})
            if not isinstance(blocks, dict):
                logger.error(f"–ö–ª—é—á 'blocks' –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä—ë–º, –Ω–æ –ø–æ–ª—É—á–µ–Ω {type(blocks)}; —Å–±—Ä–æ—Å.")
                blocks = {}

            # –û—á–∏—Å—Ç–∏–º –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
            self.topics_by_block.clear()
            self.topic_list_for_pagination.clear()
            self.topic_index_map.clear()

            # –ù–∞–ø–æ–ª–Ω—è–µ–º –∏–Ω–¥–µ–∫—Å—ã —Ç–µ–º
            idx = 0
            for block, topics in blocks.items():
                if not isinstance(topics, list):
                    logger.warning(f"–î–ª—è –±–ª–æ–∫–∞ {block} –æ–∂–∏–¥–∞–µ—Ç—Å—è —Å–ø–∏—Å–æ–∫, –ø–æ–ª—É—á–µ–Ω {type(topics)}; –ø—Ä–æ–ø—É—Å–∫–∞–µ–º.")
                    continue
                for topic in topics:
                    self.topics_by_block[block].append((idx, topic))
                    self.topic_list_for_pagination.append((idx, topic))
                    self.topic_index_map[idx] = topic
                    idx += 1

            logger.info(f"Loaded {len(self.topic_list_for_pagination)} topics from blocks.")

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ PlanBotData: {e}", exc_info=True)
            # –û–±–Ω—É–ª—è–µ–º –≤—Å—ë, —á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–æ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è
            self.plans_data = {}
            self.topics_by_block.clear()
            self.topic_list_for_pagination.clear()
            self.topic_index_map.clear()
        finally:
            logger.info("<<< –í—ã—Ö–æ–¥ –∏–∑ PlanBotData._load_data")


    # –ü—Ä–∏–º–µ—Ä –º–µ—Ç–æ–¥–∞ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –≤—Å–µ—Ö —Ç–µ–º (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç –ª–æ–≥–∏–∫–∏ _load_data)
    def get_all_topics_list(self) -> List[Tuple[int, str]]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ (index, topic) –¥–ª—è –ø–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω–æ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞.
        """
        return self.topic_list_for_pagination


    # –ü—Ä–∏–º–µ—Ä –º–µ—Ç–æ–¥–∞ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Ç–µ–º–µ
    def get_plan_data(self, topic_name):
        # –¢–µ–ø–µ—Ä—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç self.plans_data, –∫–æ—Ç–æ—Ä—ã–π –±—ã–ª –æ–±—Ä–∞–±–æ—Ç–∞–Ω –≤ _load_data
        return self.plans_data.get(topic_name)
        
    def lemmatize_text(self, text: str) -> List[str]:
        if not self._morph:
            logger.error("MorphAnalyzer –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞.")
            return re.findall(r'\b\w+\b', text.lower())
# 2) –ü–∞—Ä—Å–∏–Ω–≥ –∏ –æ—Ü–µ–Ω–∫–∞ –ø–ª–∞–Ω–∞:
def parse_user_plan(text: str) -> List[Tuple[str, List[str]]]:
    parsed_plan = []
    current_point_text = None
    current_subpoints = []
    point_pattern = re.compile(r"^\s*(\d+)[\.\)\-]\s*(.*)")
    subpoint_pattern = re.compile(r"^\s*(?:([–∞-—èa-z])[\.\)]|([*\-]))\s*(.*)")
    lines = text.strip().split('\n')
    for line in lines:
        stripped_line = line.strip()
        if not stripped_line: continue
        point_match = point_pattern.match(stripped_line)
        subpoint_match = subpoint_pattern.match(stripped_line)
        if point_match:
            if current_point_text is not None:
                parsed_plan.append((current_point_text, current_subpoints))
            current_point_text = point_match.group(2).strip()
            current_subpoints = []
            logger.debug(f"–†–∞—Å–ø–∞—Ä—Å–µ–Ω –ø—É–Ω–∫—Ç: {point_match.group(1)}. –¢–µ–∫—Å—Ç: '{current_point_text}'")
        elif subpoint_match and current_point_text is not None:
            subpoint_text = subpoint_match.group(3).strip()
            if subpoint_text:
                current_subpoints.append(subpoint_text)
                marker = subpoint_match.group(1) or subpoint_match.group(2)
                logger.debug(f"–†–∞—Å–ø–∞—Ä—Å–µ–Ω –ø–æ–¥–ø—É–Ω–∫—Ç ({marker}): '{subpoint_text}'")
            else:
                logger.debug(f"–ü—Ä–æ–ø—É—â–µ–Ω –ø—É—Å—Ç–æ–π –ø–æ–¥–ø—É–Ω–∫—Ç: {stripped_line}")
        elif current_point_text is not None and stripped_line: # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ–ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
            # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –ø—É–Ω–∫—Ç–∞ —Å –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏
            current_point_text += " " + stripped_line
            logger.debug(f"–°—Ç—Ä–æ–∫–∞ '{stripped_line}' –¥–æ–±–∞–≤–ª–µ–Ω–∞ –∫ —Ç–µ–∫—Å—Ç—É –ø—É–Ω–∫—Ç–∞: '{current_point_text}'")
        else:
            logger.debug(f"–ò–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç—Å—è —Å—Ç—Ä–æ–∫–∞ –¥–æ –ø–µ—Ä–≤–æ–≥–æ –ø—É–Ω–∫—Ç–∞: '{stripped_line}'")
    if current_point_text is not None:
        parsed_plan.append((current_point_text, current_subpoints))
    if not parsed_plan and text.strip():
         logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–ª–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:\n{text[:200]}...")
    return parsed_plan

def _check_plan_structure(parsed_plan: List[Tuple[str, List[str]]], ideal_plan_data: dict) -> Tuple[int, int, int, int]:
    num_user_points = len(parsed_plan)
    detailed_points_count = 0
    detailed_points_with_enough_subpoints = 0
    subpoints_low_count = 0

    for _, subpoints in parsed_plan:
        num_subpoints = len(subpoints)
        if num_subpoints > 0:
             detailed_points_count += 1
             if num_subpoints >= ideal_plan_data.get("min_subpoints", 3):
                  detailed_points_with_enough_subpoints += 1
             elif num_subpoints > 0 : # –ü–æ–¥—Å—á–µ—Ç –ø—É–Ω–∫—Ç–æ–≤ —Å 1-2 –ø–æ–¥–ø—É–Ω–∫—Ç–∞–º–∏
                  subpoints_low_count += 1

    return num_user_points, detailed_points_count, detailed_points_with_enough_subpoints, subpoints_low_count


def _check_plan_keywords(user_plan_text: str, ideal_plan_data: dict, bot_data: PlanBotData) -> Tuple[int, List[str], List[str]]:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∏–∑ —ç—Ç–∞–ª–æ–Ω–Ω–æ–≥–æ –ø–ª–∞–Ω–∞ –≤ –ø–ª–∞–Ω–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
    ideal_points = ideal_plan_data.get("points_data", [])
    num_found_key = 0
    hit_details = []  # –ù–∞–π–¥–µ–Ω–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
    missed_points_details = []  # –ù–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ
    error_feedback = []

    user_plan_lemmas_set = set(bot_data.lemmatize_text(user_plan_text))
    if not user_plan_lemmas_set:
        logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –ª–µ–º–º—ã –∏–∑ –ø–ª–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.")
        error_feedback.append("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ç–µ–∫—Å—Ç –≤–∞—à–µ–≥–æ –ø–ª–∞–Ω–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤.")
        return 0, [], error_feedback

    num_potentially_key_ideal = sum(1 for p in ideal_points if isinstance(p, dict) and p.get("is_potentially_key"))

    for ideal_point_data in ideal_points:
        if not isinstance(ideal_point_data, dict):
            logger.warning(f"–≠–ª–µ–º–µ–Ω—Ç –≤ 'points_data' –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Å–ª–æ–≤–∞—Ä–µ–º: {ideal_point_data}")
            continue

        ideal_point_text = ideal_point_data.get('point_text', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø—É–Ω–∫—Ç')
        lemmatized_keywords = ideal_point_data.get('lemmatized_keywords', [])
        is_key = ideal_point_data.get("is_potentially_key", False)

        if not lemmatized_keywords:
            if is_key:
                missed_points_details.append(f"‚ùì –ü—É–Ω–∫—Ç <i>{ideal_point_text}</i> (–∫–ª—é—á–µ–≤–æ–π): –ù–µ—Ç —Å–ª–æ–≤ –¥–ª—è –∞–≤—Ç–æ–ø—Ä–æ–≤–µ—Ä–∫–∏.")
            continue

        num_keywords = len(lemmatized_keywords)
        required_matches = (
            1 if num_keywords <= 2 else
            2 if num_keywords <= 5 else
            max(2, math.ceil(num_keywords * 0.4))
        )

        matches_count = 0
        found_kws_in_point = []
        for lemma_kw in lemmatized_keywords:
            if lemma_kw in user_plan_lemmas_set:
                matches_count += 1
                found_kws_in_point.append(lemma_kw)

        if matches_count >= required_matches:
            mark = "‚úÖ" if is_key else "‚ÑπÔ∏è"
            status_text = "–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π" if is_key else "–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π"
            hit_details.append(
                f"{mark} –ü—É–Ω–∫—Ç <i>{ideal_point_text}</i> ({status_text}): –ù–∞–π–¥–µ–Ω–æ —Å–ª–æ–≤: {matches_count}/{num_keywords} (—Ç—Ä–µ–±—É–µ—Ç—Å—è ‚â• {required_matches})"
            )
            if is_key:
                num_found_key += 1
        elif is_key:
            reason = (
                f"–Ω–∞–π–¥–µ–Ω–æ {matches_count} < {required_matches} –∫–ª—é—á. —Å–ª–æ–≤"
                if matches_count > 0
                else "–∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"
            )
            missed_points_details.append(
                f"‚ö†Ô∏è –ü—É–Ω–∫—Ç <i>{ideal_point_text}</i> (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π): –ù–µ –∑–∞—Å—á–∏—Ç–∞–Ω ({reason})"
            )
            logger.debug(f"–ü—É–Ω–∫—Ç '{ideal_point_text}' –Ω–µ –∑–∞—Å—á–∏—Ç–∞–Ω (–Ω–∞–¥–æ ‚â• {required_matches}, –Ω–∞–π–¥–µ–Ω–æ {matches_count}: {found_kws_in_point})")

    keyword_feedback = [
        f"<b>üîë –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π —Å –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–´–ú–ò –ø—É–Ω–∫—Ç–∞–º–∏:</b> "
        f"{num_found_key} –∏–∑ {num_potentially_key_ideal}"
    ]

    if hit_details:
        keyword_feedback.append("<b>–ù–∞–π–¥–µ–Ω–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —Å –ø—É–Ω–∫—Ç–∞–º–∏ —ç—Ç–∞–ª–æ–Ω–∞:</b>")
        keyword_feedback.extend([f"‚ñ´Ô∏è {detail}" for detail in hit_details])
    if missed_points_details:
        keyword_feedback.append("<b>–ù–µ –∑–∞—Å—á–∏—Ç–∞–Ω–Ω—ã–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø—É–Ω–∫—Ç—ã —ç—Ç–∞–ª–æ–Ω–∞:</b>")
        keyword_feedback.extend([f"‚ñ´Ô∏è {detail}" for detail in missed_points_details])

    return num_found_key, keyword_feedback, error_feedback



def _calculate_score(num_user_points: int, detailed_points_count: int, detailed_points_with_enough_subpoints: int, num_found_key: int, ideal_plan_data: dict) -> Tuple[int, int, List[str]]:
    """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –±–∞–ª–ª—ã –ö1 –∏ –ö2 –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ–≥–æ –∏ —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞."""
    k1_score = 0
    k2_score = 0
    score_explanation = []

    min_points_required = ideal_plan_data.get("min_points", 3)
    min_detailed_points_required = ideal_plan_data.get("min_detailed_points", 2)
    min_subpoints_req = ideal_plan_data.get("min_subpoints", 3)

    has_min_points = num_user_points >= min_points_required
    has_min_detailed = detailed_points_with_enough_subpoints >= min_detailed_points_required
    has_one_detailed_enough = detailed_points_with_enough_subpoints >= 1
    has_at_least_one_detailed = detailed_points_count >= 1
    key_points_sufficient = num_found_key >= min_detailed_points_required

    if has_min_points and has_min_detailed and key_points_sufficient:
        k1_score = 3
        score_explanation.append(f"‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∞: {num_user_points} –ø. (‚â•{min_points_required}), –∏–∑ –Ω–∏—Ö {detailed_points_with_enough_subpoints} –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã {min_subpoints_req}+ –ø–æ–¥–ø—É–Ω–∫—Ç–∞–º–∏ (‚â•{min_detailed_points_required}).")
        score_explanation.append(f"‚úÖ –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ: –ù–∞–π–¥–µ–Ω–æ {num_found_key} –æ–±—è–∑. –ø—É–Ω–∫—Ç–æ–≤ –ø–æ —Å–ª–æ–≤–∞–º (‚â•{min_detailed_points_required}, –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ).")
    elif has_min_points and key_points_sufficient and (not has_min_detailed and has_one_detailed_enough):
        k1_score = 2
        score_explanation.append(f"‚ö†Ô∏è –°—Ç—Ä—É–∫—Ç—É—Ä–∞: {num_user_points} –ø. (‚â•{min_points_required}), –Ω–æ —Ç–æ–ª—å–∫–æ {detailed_points_with_enough_subpoints} –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω(—ã) {min_subpoints_req}+ –ø–æ–¥–ø—É–Ω–∫—Ç–∞–º–∏ (<{min_detailed_points_required}).")
        score_explanation.append(f"‚úÖ –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ: –ù–∞–π–¥–µ–Ω–æ {num_found_key} –æ–±—è–∑. –ø—É–Ω–∫—Ç–æ–≤ –ø–æ —Å–ª–æ–≤–∞–º (‚â•{min_detailed_points_required}, –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ).")
    elif has_min_points and has_min_detailed and not key_points_sufficient:
        k1_score = 2
        score_explanation.append(f"‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∞: {num_user_points} –ø. (‚â•{min_points_required}), {detailed_points_with_enough_subpoints} –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã {min_subpoints_req}+ –ø–æ–¥–ø—É–Ω–∫—Ç–∞–º–∏ (‚â•{min_detailed_points_required}).")
        score_explanation.append(f"‚ö†Ô∏è –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ: –ù–∞–π–¥–µ–Ω–æ {num_found_key} –æ–±—è–∑. –ø—É–Ω–∫—Ç–æ–≤ –ø–æ —Å–ª–æ–≤–∞–º (<{min_detailed_points_required}, –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ).")
    elif has_min_points and has_at_least_one_detailed and key_points_sufficient and not has_one_detailed_enough:
        k1_score = 1
        score_explanation.append(f"‚ö†Ô∏è –°—Ç—Ä—É–∫—Ç—É—Ä–∞: {num_user_points} –ø. (‚â•{min_points_required}), –Ω–æ {detailed_points_with_enough_subpoints} –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω(—ã) {min_subpoints_req}+ –ø–æ–¥–ø—É–Ω–∫—Ç–∞–º–∏ (=0).")
        score_explanation.append(f"‚úÖ –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ: –ù–∞–π–¥–µ–Ω–æ {num_found_key} –æ–±—è–∑. –ø—É–Ω–∫—Ç–æ–≤ –ø–æ —Å–ª–æ–≤–∞–º (‚â•{min_detailed_points_required}, –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ).")
    else:
        k1_score = 0
        struct_issue = ""
        if not has_min_points: struct_issue += f"–º–µ–Ω–µ–µ {min_points_required} –ø.; "
        if not has_min_detailed: struct_issue += f"–º–µ–Ω–µ–µ {min_detailed_points_required} –¥–µ—Ç–∞–ª–∏–∑–∏—Ä. {min_subpoints_req}+ –ø–æ–¥–ø.; "
        content_issue = f"–Ω–∞–π–¥–µ–Ω–æ {num_found_key} (<{min_detailed_points_required}) –æ–±—è–∑. –ø—É–Ω–∫—Ç–æ–≤" if not key_points_sufficient else ""
        score_explanation.append(f"‚ùå –ü–ª–∞–Ω –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∫—Ä–∏—Ç–µ—Ä–∏—è–º –ö1 ({struct_issue.strip()}; {content_issue})")

    if k1_score == 3:
        k2_score = 1
        score_explanation.append("‚úÖ –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å (–ö2): +1 –±–∞–ª–ª (–≤—ã—Å—Ç–∞–≤–ª—è–µ—Ç—Å—è –ø—Ä–∏ –ö1=3). –ë–æ—Ç –Ω–µ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –æ—à–∏–±–∫–∏/–Ω–µ—Ç–æ—á–Ω–æ—Å—Ç–∏ –≤ —Ç–µ–∫—Å—Ç–µ.")
    else:
        k2_score = 0
        score_explanation.append("‚ûñ –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å (–ö2): 0 –±–∞–ª–ª–æ–≤ (—Ç.–∫. –ö1 < 3).")

    return k1_score, k2_score, score_explanation


def _format_evaluation_feedback(k1: int, k2: int, score_explanation: List[str], structure_feedback: List[str], keyword_feedback: List[str], error_feedback: List[str], topic_name: str) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –∏—Ç–æ–≥–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º HTML."""
    total_score = k1 + k2
    escaped_topic_name = html.escape(str(topic_name)) if topic_name else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è —Ç–µ–º–∞"
    score_emoji = "üéâ" if total_score == 4 else "üëç" if total_score == 3 else "ü§î" if total_score > 0 else "üôÅ"

    feedback = [f"üìå <b>–¢–µ–º–∞:</b> {escaped_topic_name}\n"]
    feedback.append(f"{score_emoji} <b>–ü—Ä–µ–¥–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞: {total_score} –∏–∑ 4</b> {score_emoji}")
    feedback.append(f"  –ö1 (–†–∞—Å–∫—Ä—ã—Ç–∏–µ —Ç–µ–º—ã): <b>{k1} / 3</b>")
    feedback.append(f"  –ö2 (–ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å):    <b>{k2} / 1</b>") # –í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –ø—Ä–æ–±–µ–ª–∞–º–∏

    if score_explanation:
        feedback.append("\n  üìù <b>–ü–æ—è—Å–Ω–µ–Ω–∏—è –∫ –±–∞–ª–ª–∞–º –ö1:</b>")
        feedback.extend([f"      - {exp}" for exp in score_explanation])

    important_note = "<i>‚ùóÔ∏è –í–∞–∂–Ω–æ: –û—Ü–µ–Ω–∫–∞ –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–∞—è. –ë–æ—Ç –Ω–µ –∑–∞–º–µ–Ω—è–µ—Ç —ç–∫—Å–ø–µ—Ä—Ç–∞ –ï–ì–≠ –∏ –Ω–µ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–æ–∫ (–ö2).</i>"
    feedback.append(f"\n  {important_note}")
    feedback.append("\n------------------------------------\n")
    feedback.append("üîç <b>–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑:</b>\n")

    if error_feedback:
        feedback.append("<b>üö´ –û—à–∏–±–∫–∏ –∞–Ω–∞–ª–∏–∑–∞:</b>")
        feedback.extend([f"    - {err}" for err in error_feedback])
        feedback.append("")

    if structure_feedback:
        header = html.escape(structure_feedback[0].replace('* **','').replace('**','').strip())
        feedback.append(f"üèóÔ∏è {structure_feedback[0]}")  # –£–∂–µ —Å–æ–¥–µ—Ä–∂–∏—Ç <b>...</b>
        feedback.extend([f"    {line.strip()}" for line in structure_feedback[1:]])
        feedback.append("")

    if keyword_feedback:
        keyword_headers = {
            "–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π —Å –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–´–ú–ò –ø—É–Ω–∫—Ç–∞–º–∏:",
            "–ù–∞–π–¥–µ–Ω–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —Å –ø—É–Ω–∫—Ç–∞–º–∏ —ç—Ç–∞–ª–æ–Ω–∞:",
            "–ù–µ –∑–∞—Å—á–∏—Ç–∞–Ω–Ω—ã–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø—É–Ω–∫—Ç—ã —ç—Ç–∞–ª–æ–Ω–∞:"
        }
        first_item_in_list = True
        for i, line in enumerate(keyword_feedback):
            line_stripped = line.strip()
            cleaned_line = line_stripped.replace("* **", "").replace("**", "").strip()
            is_header = any(cleaned_line.startswith(html.escape(h)) for h in keyword_headers) or (i==0 and "–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π" in cleaned_line)

            if is_header:
                if not first_item_in_list: feedback.append("")
                feedback.append(f"üîë <b>{cleaned_line}</b>")
                first_item_in_list = True
            elif line_stripped:
                feedback.append(f"    {cleaned_line}") # –û—Ç—Å—Ç—É–ø –¥–ª—è —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å–ø–∏—Å–∫–∞
                first_item_in_list = False

    return "\n".join(feedback)

def evaluate_plan(
    user_plan_text: str,
    ideal_plan_data: dict,
    bot_data: PlanBotData,
    topic_name: str
) -> str:
    """
    –†–∞–∑–±–∏—Ä–∞–µ—Ç –∏ –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø–ª–∞–Ω:
     1) –ø—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É (–ø—É–Ω–∫—Ç—ã/–ø–æ–¥–ø—É–Ω–∫—Ç—ã);
     2) –∏—â–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞;
     3) –≤—ã—á–∏—Å–ª—è–µ—Ç –±–∞–ª–ª—ã K1 –∏ K2;
     4) —Å–æ–±–∏—Ä–∞–µ—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç HTML-—Ñ–∏–¥–±–µ–∫.
    """
    # 0. –ü–∞—Ä—Å–∏–º –ø–ª–∞–Ω
    parsed = parse_user_plan(user_plan_text)
    if not parsed and user_plan_text.strip():
        return "<b>–û—à–∏–±–∫–∞ —Ä–∞–∑–±–æ—Ä–∞ –ø–ª–∞–Ω–∞!</b> –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç –Ω—É–º–µ—Ä–∞—Ü–∏–∏."
    if not parsed:
        return "–ü—É—Å—Ç–æ–π –ø–ª–∞–Ω. –ü—Ä–∏—à–ª–∏—Ç–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–∞—à –≤–∞—Ä–∏–∞–Ω—Ç."

    # 1. –°—Ç—Ä—É–∫—Ç—É—Ä–∞
    pts, det_cnt, det_enough_cnt, det_low_cnt = _check_plan_structure(
        parsed, ideal_plan_data
    )
    # –°–æ–±–∏—Ä–∞–µ–º –ø–æ—è—Å–Ω–µ–Ω–∏—è –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ
    struct_fb = [
        f"‚Ä¢ –í—Å–µ–≥–æ –ø—É–Ω–∫—Ç–æ–≤: {pts}",
        f"‚Ä¢ –î–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤: {det_cnt}",
        f"‚Ä¢ –ü—É–Ω–∫—Ç–æ–≤ —Å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–º —á–∏—Å–ª–æ–º –ø–æ–¥–ø—É–Ω–∫—Ç–æ–≤: {det_enough_cnt}",
        f"‚Ä¢ –ü—É–Ω–∫—Ç–æ–≤ —Å –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–º —á–∏—Å–ª–æ–º –ø–æ–¥–ø—É–Ω–∫—Ç–æ–≤: {det_low_cnt}"
    ]

    # 2. –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
    found_key, keyword_fb, error_fb = _check_plan_keywords(
        user_plan_text, ideal_plan_data, bot_data
    )

    # 3. –°—á–∏—Ç–∞–µ–º –±–∞–ª–ª—ã
    k1, k2, score_expl = _calculate_score(
        pts, det_cnt, det_enough_cnt, found_key, ideal_plan_data
    )

    # 4. –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π —Ñ–∏–¥–±–µ–∫
    feedback = _format_evaluation_feedback(
        k1=k1,
        k2=k2,
        score_explanation=score_expl,
        structure_feedback=struct_fb,
        keyword_feedback=keyword_fb,
        error_feedback=error_fb,
        topic_name=topic_name
    )

    return feedback

# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
# 3) Inline-–∫–ª–∞–≤–∏–∞—Ç—É—Ä–∞ –¥–ª—è —Ñ–∏–¥–±–µ–∫–∞
FEEDBACK_KB = InlineKeyboardMarkup([
    [
        InlineKeyboardButton("üè† –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é", callback_data="back_main"),
        InlineKeyboardButton("‚û°Ô∏è –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å",   callback_data="next_topic")
    ]
])
