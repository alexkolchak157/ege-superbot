"""
–°–µ—Ä–≤–∏—Å –¥–ª—è AI –ø—Ä–æ–≤–µ—Ä–∫–∏ –æ—Ç–≤–µ—Ç–æ–≤ —É—á–µ–Ω–∏–∫–æ–≤ –≤ –¥–æ–º–∞—à–Ω–∏—Ö –∑–∞–¥–∞–Ω–∏—è—Ö.
"""

import logging
from typing import Optional, Dict, Tuple

logger = logging.getLogger(__name__)


async def evaluate_homework_answer(
    task_module: str,
    question_data: Dict,
    user_answer: str,
    user_id: int
) -> Tuple[bool, str]:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ—Ç–≤–µ—Ç —É—á–µ–Ω–∏–∫–∞ —á–µ—Ä–µ–∑ AI evaluator —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–≥–æ –º–æ–¥—É–ª—è.

    Args:
        task_module: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥—É–ª—è ('task19', 'task20', 'task24', 'task25')
        question_data: –î–∞–Ω–Ω—ã–µ –≤–æ–ø—Ä–æ—Å–∞ –∏–∑ question_loader
        user_answer: –û—Ç–≤–µ—Ç —É—á–µ–Ω–∏–∫–∞
        user_id: ID —É—á–µ–Ω–∏–∫–∞

    Returns:
        Tuple[bool, str]: (is_correct, feedback_text)
        - is_correct: True –µ—Å–ª–∏ –æ—Ç–≤–µ—Ç –ø—Ä–∏–Ω—è—Ç (–Ω–∞–±—Ä–∞–Ω–æ > 50% –±–∞–ª–ª–æ–≤)
        - feedback_text: –¢–µ–∫—Å—Ç –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ –¥–ª—è —É—á–µ–Ω–∏–∫–∞
    """
    try:
        if task_module == 'task19':
            return await _evaluate_task19(question_data, user_answer, user_id)
        elif task_module == 'task20':
            return await _evaluate_task20(question_data, user_answer, user_id)
        elif task_module == 'task24':
            return await _evaluate_task24(question_data, user_answer, user_id)
        elif task_module == 'task25':
            return await _evaluate_task25(question_data, user_answer, user_id)
        else:
            logger.warning(f"Unknown task module: {task_module}")
            return False, f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –∑–∞–¥–∞–Ω–∏—è: {task_module}"

    except Exception as e:
        logger.error(f"Error evaluating answer for {task_module}: {e}", exc_info=True)
        return False, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –æ—Ç–≤–µ—Ç–∞: {str(e)}"


async def _evaluate_task19(question_data: Dict, user_answer: str, user_id: int) -> Tuple[bool, str]:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç–≤–µ—Ç–∞ –¥–ª—è task19 (–ø—Ä–∏–º–µ—Ä—ã —Å –æ–±—â–µ—Å—Ç–≤–æ–∑–Ω–∞–Ω–∏–µ–º)"""
    try:
        from task19.evaluator import Task19AIEvaluator, StrictnessLevel
        from core.types import EvaluationResult

        # –°–æ–∑–¥–∞–µ–º evaluator
        evaluator = Task19AIEvaluator(strictness=StrictnessLevel.STANDARD)

        # –í—ã–∑—ã–≤–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É
        topic = question_data.get('title', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è —Ç–µ–º–∞')
        task_text = question_data.get('task_text', '')

        result: EvaluationResult = await evaluator.evaluate(
            answer=user_answer,
            topic=topic,
            task_text=task_text
        )

        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å
        is_correct = result.total_score >= (result.max_score / 2)  # >= 50% –±–∞–ª–ª–æ–≤

        feedback = f"üìä <b>–†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏:</b>\n\n"
        feedback += f"–ë–∞–ª–ª—ã: {result.total_score}/{result.max_score}\n\n"
        feedback += f"<b>–û–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å:</b>\n{result.feedback}"

        if result.warnings:
            feedback += f"\n\n‚ö†Ô∏è <b>–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è:</b>\n"
            feedback += "\n".join(f"‚Ä¢ {w}" for w in result.warnings)

        if result.suggestions:
            feedback += f"\n\nüí° <b>–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:</b>\n"
            feedback += "\n".join(f"‚Ä¢ {s}" for s in result.suggestions)

        return is_correct, feedback

    except ImportError as e:
        logger.warning(f"Task19 evaluator not available: {e}")
        return True, "‚úÖ –û—Ç–≤–µ—Ç –ø—Ä–∏–Ω—è—Ç (AI –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞)"
    except Exception as e:
        logger.error(f"Error in task19 evaluation: {e}", exc_info=True)
        return False, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ: {str(e)}"


async def _evaluate_task20(question_data: Dict, user_answer: str, user_id: int) -> Tuple[bool, str]:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç–≤–µ—Ç–∞ –¥–ª—è task20 (–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏)"""
    try:
        from task20.evaluator import Task20AIEvaluator
        from core.types import EvaluationResult

        # –°–æ–∑–¥–∞–µ–º evaluator
        evaluator = Task20AIEvaluator()

        # –í—ã–∑—ã–≤–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É
        topic = question_data.get('title', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è —Ç–µ–º–∞')
        task_text = question_data.get('task_text', '')

        result: EvaluationResult = await evaluator.evaluate(
            answer=user_answer,
            topic=topic,
            task_text=task_text
        )

        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å
        is_correct = result.total_score >= (result.max_score / 2)

        feedback = f"üìä <b>–†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏:</b>\n\n"
        feedback += f"–ë–∞–ª–ª—ã: {result.total_score}/{result.max_score}\n\n"
        feedback += f"<b>–û–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å:</b>\n{result.feedback}"

        if result.warnings:
            feedback += f"\n\n‚ö†Ô∏è <b>–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è:</b>\n"
            feedback += "\n".join(f"‚Ä¢ {w}" for w in result.warnings)

        if result.suggestions:
            feedback += f"\n\nüí° <b>–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:</b>\n"
            feedback += "\n".join(f"‚Ä¢ {s}" for s in result.suggestions)

        return is_correct, feedback

    except ImportError as e:
        logger.warning(f"Task20 evaluator not available: {e}")
        return True, "‚úÖ –û—Ç–≤–µ—Ç –ø—Ä–∏–Ω—è—Ç (AI –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞)"
    except Exception as e:
        logger.error(f"Error in task20 evaluation: {e}", exc_info=True)
        return False, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ: {str(e)}"


async def _evaluate_task24(question_data: Dict, user_answer: str, user_id: int) -> Tuple[bool, str]:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç–≤–µ—Ç–∞ –¥–ª—è task24 (—Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—ã–π –ø–ª–∞–Ω)"""
    try:
        from task24.checker import evaluate_plan_with_ai
        from task24.handlers import plan_bot_data  # –ì–ª–æ–±–∞–ª—å–Ω—ã–π –æ–±—ä–µ–∫—Ç —Å –¥–∞–Ω–Ω—ã–º–∏ –ø–ª–∞–Ω–æ–≤

        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ —ç—Ç–∞–ª–æ–Ω–Ω–æ–≥–æ –ø–ª–∞–Ω–∞
        topic_name = question_data.get('title', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è —Ç–µ–º–∞')

        # –§–æ—Ä–º–∏—Ä—É–µ–º ideal_plan_data –∏–∑ question_data
        ideal_plan_data = {
            'full_plan': question_data.get('full_plan', []),
            'points_data': question_data.get('points_data', []),
            'min_points': question_data.get('min_points', 3),
            'min_detailed_points': question_data.get('min_detailed_points', 2),
            'min_subpoints': question_data.get('min_subpoints', 3)
        }

        # –í—ã–∑—ã–≤–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É
        feedback_text = await evaluate_plan_with_ai(
            user_plan_text=user_answer,
            ideal_plan_data=ideal_plan_data,
            bot_data=plan_bot_data,
            topic_name=topic_name,
            use_ai=True,
            user_id=user_id
        )

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –±–∞–ª–ª—ã –∏–∑ feedback
        import re
        k1_match = re.search(r'–ö1.*?(\d+)/3', feedback_text)
        k2_match = re.search(r'–ö2.*?(\d+)/1', feedback_text)
        k1 = int(k1_match.group(1)) if k1_match else 0
        k2 = int(k2_match.group(1)) if k2_match else 0

        total_score = k1 + k2
        max_score = 4

        is_correct = total_score >= (max_score / 2)  # >= 2 –±–∞–ª–ª–æ–≤ –∏–∑ 4

        feedback = f"üìä <b>–†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–ª–∞–Ω–∞:</b>\n\n"
        feedback += feedback_text

        return is_correct, feedback

    except ImportError as e:
        logger.warning(f"Task24 checker not available: {e}")
        return True, "‚úÖ –û—Ç–≤–µ—Ç –ø—Ä–∏–Ω—è—Ç (AI –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞)"
    except Exception as e:
        logger.error(f"Error in task24 evaluation: {e}", exc_info=True)
        return False, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ: {str(e)}"


async def _evaluate_task25(question_data: Dict, user_answer: str, user_id: int) -> Tuple[bool, str]:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç–≤–µ—Ç–∞ –¥–ª—è task25 (—ç—Å—Å–µ)"""
    try:
        from task25.evaluator import Task25AIEvaluator
        from core.types import EvaluationResult

        # –°–æ–∑–¥–∞–µ–º evaluator
        evaluator = Task25AIEvaluator()

        # –í—ã–∑—ã–≤–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É
        result: EvaluationResult = await evaluator.evaluate(
            answer=user_answer,
            topic=question_data,  # –ü–µ—Ä–µ–¥–∞–µ–º –≤–µ—Å—å question_data –∫–∞–∫ topic
            user_id=user_id
        )

        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å
        is_correct = result.total_score >= (result.max_score / 2)

        feedback = f"üìä <b>–†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏:</b>\n\n"
        feedback += f"–ë–∞–ª–ª—ã: {result.total_score}/{result.max_score}\n\n"

        # –î–æ–±–∞–≤–ª—è–µ–º –¥–µ—Ç–∞–ª–∏ –ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—è–º
        if result.criteria_scores:
            feedback += "<b>–ü–æ –∫—Ä–∏—Ç–µ—Ä–∏—è–º:</b>\n"
            for criterion, score in result.criteria_scores.items():
                feedback += f"‚Ä¢ {criterion}: {score}\n"
            feedback += "\n"

        feedback += f"<b>–û–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å:</b>\n{result.feedback}"

        if result.warnings:
            feedback += f"\n\n‚ö†Ô∏è <b>–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è:</b>\n"
            feedback += "\n".join(f"‚Ä¢ {w}" for w in result.warnings)

        if result.suggestions:
            feedback += f"\n\nüí° <b>–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:</b>\n"
            feedback += "\n".join(f"‚Ä¢ {s}" for s in result.suggestions)

        return is_correct, feedback

    except ImportError as e:
        logger.warning(f"Task25 evaluator not available: {e}")
        return True, "‚úÖ –û—Ç–≤–µ—Ç –ø—Ä–∏–Ω—è—Ç (AI –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞)"
    except Exception as e:
        logger.error(f"Error in task25 evaluation: {e}", exc_info=True)
        return False, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ: {str(e)}"
